{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 10\n",
    "\n",
    "### Today's Topic:\n",
    "* Batch Normalization\n",
    "* Residual Neural Network\n",
    "* Pytorch utilizing GPU speedup \n",
    "* Torchani aev computer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "Batch normalization (also known as batch norm) is a method used to make artificial neural networks faster and more stable through normalization of the layers' inputs by re-centering and re-scalin\n",
    "Documentation: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html <br>\n",
    "expected input of size (N, C, H, W) <br>\n",
    "the Batch Normalization is done over the C dimension, computing statistics on (N, H, W) slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/msse-python/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 100, 35, 45])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "inp = torch.randn(20, 100, 35, 45)\n",
    "bn = nn.BatchNorm2d(100)\n",
    "output = bn(inp)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.ModuleList([nn.Conv2d(1,6,kernel_size=3,padding=1), #before pooling (B,6,32,32)\n",
    "                                  nn.Conv2d(6,24,kernel_size=3,padding=1), # (B,24,16,16)\n",
    "                                  nn.Conv2d(24,12,kernel_size=5)]) # (B,12,4,4)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc = nn.ModuleList([nn.Linear(192,192),nn.Linear(192,10)])\n",
    "        self.activation = nn.ReLU()\n",
    "        self.bn = [nn.BatchNorm2d(6), nn.BatchNorm2d(24), nn.BatchNorm2d(12)]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i in range(2):\n",
    "            x = self.pooling(self.activation(self.bn[i](self.conv[i](x))))\n",
    "        x = nn.Flatten()(self.activation(self.bn[2](self.conv[2](x)))) #(N, C, W, H) #(N, C*W*H)\n",
    "        x = self.activation(self.fc[0](x))\n",
    "        x = nn.Softmax(dim=-1)(self.fc[1](x))\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv): ModuleList(\n",
      "    (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(6, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(24, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  )\n",
      "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): ModuleList(\n",
      "    (0): Linear(in_features=192, out_features=192, bias=True)\n",
      "    (1): Linear(in_features=192, out_features=10, bias=True)\n",
      "  )\n",
      "  (activation): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn(torch.randn(20, 1, 32, 32)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additive vs concatenative skip connections\n",
    "\n",
    "![](Additive-skip-connections-vs-concatenative-skip-connections-Rectangles-represent-data.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.ModuleList([nn.Conv2d(1,6,kernel_size=3,padding=1), #before pooling (B,6,32,32)\n",
    "                                  nn.Conv2d(6,24,kernel_size=3,padding=1), # (B,24,16,16)\n",
    "                                  nn.Conv2d(24,12,kernel_size=5)]) # (B,12,4,4)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc = nn.ModuleList([nn.Linear(192,192),nn.Linear(192,10)])\n",
    "        self.activation = nn.ReLU()\n",
    "        self.bn = [nn.BatchNorm2d(6), nn.BatchNorm2d(24), nn.BatchNorm2d(12)]\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        residual = inp\n",
    "        x = self.bn[0](self.conv[0](inp))\n",
    "        x = x + residual \n",
    "        x = self.pooling(self.activation(x))\n",
    "        x = self.pooling(self.activation(self.bn[1](self.conv[1](x))))\n",
    "        x = nn.Flatten()(self.activation(self.bn[2](self.conv[2](x))))\n",
    "        residual = x\n",
    "        y = self.fc[0](x)\n",
    "        y += residual # to do the skip connection \n",
    "        y = self.activation(x)\n",
    "        y = nn.Softmax(dim=-1)(self.fc[1](y))\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv): ModuleList(\n",
      "    (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(6, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(24, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  )\n",
      "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): ModuleList(\n",
      "    (0): Linear(in_features=192, out_features=192, bias=True)\n",
      "    (1): Linear(in_features=192, out_features=10, bias=True)\n",
      "  )\n",
      "  (activation): ReLU()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3983, 0.6847, 0.3903,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 1.2575, 1.8897, 0.0000],\n",
       "        [0.0000, 0.2984, 1.1979,  ..., 0.6522, 0.0000, 1.2142],\n",
       "        ...,\n",
       "        [0.0310, 2.0298, 0.1642,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.4990, 1.7113, 0.9213,  ..., 0.0000, 0.5603, 0.0000],\n",
       "        [0.0000, 0.1663, 0.0000,  ..., 0.5010, 0.0000, 0.0000]],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CNN()\n",
    "print(net)\n",
    "net(torch.randn(20, 1, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MGCF cluster resources\n",
    "https://docs.google.com/document/d/1lIkJ6g772Ss5e-4CJ_xGjlVRfOVUq6gYnyGiEhtBc-Q/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using GPU resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking available resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the number of GPUs available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.cuda' has no attribute 'get_advice_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_advice_name\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute 'get_advice_name'"
     ]
    }
   ],
   "source": [
    "torch.cuda.get_advice_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move tensors to gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the tensors are generated on the CPU. Even the model is initialized on the CPU. Thus one has to manually ensure that the operations are done using GPU. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m2.\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mx_train\u001b[49m\u001b[38;5;241m.\u001b[39mis_cuda\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = torch.FloatTensor([0., 1., 2.])\n",
    "x_train.is_cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a common PyTorch practice to initialize a variable, usually named device that will hold the device we’re training on (CPU or GPU). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to(device)\n",
    "X_train.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same logic applies to the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move tensors back to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.cpu()\n",
    "X_train.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([0., 1., 2.])\n",
    "Y = torch.FloatTensor([0., 1., 2.])\n",
    "X = X.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X+Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X+Y).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AEV Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C', 'C', 'N', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H'] (10080, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "import torchani \n",
    "import torch\n",
    "import numpy as np\n",
    "from pyanitools import anidataloader\n",
    "# data = anidataloader(\"../../ANI1_dataset/ANI-1_release/ani_gdb_s07.h5\")\n",
    "data = anidataloader(\"../ANI-1_release/ani_gdb_s05.h5\")\n",
    "data_iter = data.__iter__()\n",
    "mols = next(data_iter)\n",
    "# Extract the data\n",
    "P = mols['path']\n",
    "X = mols['coordinates']\n",
    "E = mols['energies']\n",
    "S = mols['species']\n",
    "sm = mols['smiles']\n",
    "\n",
    "print(S, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcr = 5.2\n",
    "EtaR = torch.tensor([16], dtype=torch.float)\n",
    "ShfR = torch.tensor([0.900000,1.168750,1.437500,1.706250,1.975000,2.243750,2.51250,2.781250,3.050000,3.318750,3.587500,3.856250,4.125000,4.39375,4.662500,4.931250])\n",
    "Rca = 3.5\n",
    "EtaA = torch.tensor([8], dtype=torch.float)\n",
    "ShfA = torch.tensor([0.900000,1.550000,2.200000,2.850000], dtype=torch.float)\n",
    "ShfZ = torch.tensor([0.19634954,0.58904862,0.9817477,1.3744468,1.7671459,2.1598449,2.552544,2.945243]) \n",
    "Zeta = torch.tensor([32], dtype=torch.float)\n",
    "species_order = ['H', 'C', 'N', 'O']\n",
    "num_species = len(species_order)\n",
    "\n",
    "aev_computer = torchani.AEVComputer(Rcr, Rca, EtaR, ShfR, EtaA, Zeta, ShfA, ShfZ, num_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"H\": 0, \"C\": 1, \"N\": 2, \"O\": 3}\n",
    "species = np.array([mapping[atom] for atom in S])\n",
    "species = np.tile(species, (X.shape[0], 1))\n",
    "species = torch.tensor(species)\n",
    "X = torch.tensor(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeciesAEV(species=tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), aevs=tensor([[[3.4694e-01, 6.2468e-01, 1.1157e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [4.3388e-10, 2.3543e-06, 1.3987e-03,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [3.4627e-01, 6.2463e-01, 1.1217e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [1.2235e-06, 7.9564e-04, 5.1409e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [5.0809e-05, 7.6973e-03, 1.1560e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [5.0809e-05, 7.6973e-03, 1.1560e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[3.3922e-01, 6.2703e-01, 1.1660e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [9.0067e-10, 4.3598e-06, 2.1402e-03,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [2.8018e-01, 6.4619e-01, 1.5453e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [2.7108e-07, 2.4966e-04, 2.4087e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.2393e-05, 3.0972e-03, 7.6735e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.2393e-05, 3.0972e-03, 7.6735e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[2.9558e-01, 6.4632e-01, 1.4079e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [8.7638e-11, 7.9121e-07, 7.3804e-04,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [3.1162e-01, 6.3644e-01, 1.3399e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [5.7475e-07, 4.3001e-04, 3.3683e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [7.9958e-06, 2.3171e-03, 6.6568e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [7.9958e-06, 2.3171e-03, 6.6569e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[3.6789e-01, 6.1228e-01, 1.0215e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [2.1909e-10, 1.5356e-06, 1.1659e-03,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [3.7822e-01, 6.0697e-01, 9.6958e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [6.2884e-07, 4.9907e-04, 3.9267e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [2.4090e-05, 4.7787e-03, 9.3976e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [2.4090e-05, 4.7787e-03, 9.3976e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[3.3605e-01, 6.2764e-01, 1.1894e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.2869e-10, 1.0718e-06, 9.5987e-04,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [3.6752e-01, 6.0990e-01, 1.0407e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [3.1941e-06, 1.5452e-03, 7.4499e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [2.3699e-05, 4.7284e-03, 9.3528e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [2.3699e-05, 4.7284e-03, 9.3526e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[3.4006e-01, 6.2223e-01, 1.1915e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.5541e-10, 1.0428e-06, 8.1393e-04,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [3.6374e-01, 6.0972e-01, 1.0732e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [4.2032e-07, 3.6858e-04, 3.2445e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.2414e-05, 3.1007e-03, 7.6776e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.2414e-05, 3.1007e-03, 7.6776e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aev_computer((species, X)) #species(N, A) [0, 1, 2, 3] # coordinate: (N, A, 3) each atom has 3 dimensional coordinate\n",
    "# output: (N, A, #num_AEV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
