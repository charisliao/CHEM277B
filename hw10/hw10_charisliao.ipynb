{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4339441c",
   "metadata": {},
   "source": [
    "# MSSE 277B: Machine Learning Algorithms\n",
    "\n",
    "## Recurrent Neural Network, LSTM\n",
    "## Assigned Apr. 13 and Due Apr. 25\n",
    "\n",
    "## Student Name: Charis Liao \n",
    "\n",
    "### LSTM applied to SMILES string generation. \n",
    "Using the SMILES string from the ANI dataset with upto 6 heavy atoms, build a LSTM generative model that can generate new smiles string with given initial character.\n",
    "\n",
    "**(a) (3pt) Process the smiles strings from ANI dataset by adding a starting character at the beginning and an ending character at the end. Look over the dataset and define the vocabulary, use one hot encoding to encode your smiles strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "56bb8f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from pyanitools import anidataloader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "256fb735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "data = anidataloader(\"../ANI-1_release/ani_gdb_s06.h5\")\n",
    "data_iter = data.__iter__()\n",
    "\n",
    "# extract smiles strings \n",
    "smile_strings = []\n",
    "for mol in data_iter:\n",
    "    sm = mol['smiles']\n",
    "    sm = \"\".join(sm)\n",
    "    sm = \"^\" + sm + \"$\"\n",
    "    smile_strings.append(sm)\n",
    "    \n",
    "    \n",
    "# print(len(smile_strings))   \n",
    "# print(len(smile_strings[0]))\n",
    "# print(len(smile_strings[0][0]))\n",
    "# print(smile_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8c5214b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', 'c', 'o', 'H', '^', '$', 'n', ')', 'C', '=', '(', 'N', 'O', '[', '#', ']']\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# Get unique characters \n",
    "unique_char = list(set(\"\".join(smile_strings)))\n",
    "print(unique_char)\n",
    "print(len(unique_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c7d2ba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "vocab = {char: i for i, char in enumerate(unique_char)}\n",
    "encoder = OneHotEncoder(categories=[unique_char], handle_unknown=\"ignore\", sparse=False)\n",
    "encoder.fit(np.array(unique_char).reshape(-1,1))\n",
    "\n",
    "translate_smiles = []\n",
    "smile_indicies = []\n",
    "for s in smile_strings:\n",
    "    smile_int = np.array(list(s)).reshape(-1,1)\n",
    "    smile_indicies.append(smile_int)\n",
    "    smile_translate = encoder.transform(smile_int)\n",
    "    translate_smiles.append(smile_translate)\n",
    "\n",
    "print(len(smile_indicies[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddccee1",
   "metadata": {},
   "source": [
    "**(b) (7pt) Build a LSTM model with 1 recurrent layer. Starting with the starting character and grow a string character by character using model prediction until it reaches a ending character. Look at the string you grown, is it a valid SMILES string?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "36c06f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        # Get an output the same size as unique characters\n",
    "        \n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.lstm(x, h)\n",
    "        out = self.fc(out)\n",
    "        return out, h\n",
    "    \n",
    "    def init_state(self, batch_size):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size),\n",
    "                torch.zeros(self.n_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "38c5dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_gen(smiles, batchsize, encoder):\n",
    "    '''Create a generator that returns batches of size (batch_size,seq_leng,nchars) from smiles, \n",
    "    where seq_leng is the length of the longest smiles string and nchar is the length of one-hot encoded characters (17)\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       smiles: python list(nsmiles,nchar) smiles array shape you want to make batches from\n",
    "       batchsize: Batch size, the number of sequences per batch\n",
    "       encoder: one hot encoder\n",
    "\n",
    "    '''\n",
    "    arr=[torch.tensor(np.array(encoder.transform(np.array(s).reshape(-1,1))),dtype=torch.float) \\\n",
    "         for s in smiles] \n",
    "\n",
    "        #size (nsmiles,seq_length(variable),nchars)\n",
    "        \n",
    "    # The features\n",
    "    X = [s[:-1,:] for s in arr]\n",
    "    # The targets, shifted by one\n",
    "    y = [s[1:,:] for s in arr]\n",
    "    # pad sequence so that all smiles are the same length\n",
    "    X = nn.utils.rnn.pad_sequence(X,batch_first=True)\n",
    "    y = nn.utils.rnn.pad_sequence(y,batch_first=True)\n",
    "\n",
    "    num_batches = len(arr) // batchsize\n",
    "    \n",
    "    for i in range(len(arr)//batchsize):\n",
    "        yield X[i*batchsize:(i+1)*batchsize],y[i*batchsize:(i+1)*batchsize]\n",
    "        \n",
    "    #drop last batch that is not the same size due to hidden state constraint\n",
    "#     if len(arr) % batchsize != 0:\n",
    "#         num_dropped = len(arr) % batchsize\n",
    "#         X_last = X[-num_dropped:]\n",
    "#         y_last = y[-num_dropped:]\n",
    "#         X = X[:-num_dropped]\n",
    "#         y = y[:-num_dropped]\n",
    "#         num_batches -= 1\n",
    "#         yield X_last, y_last\n",
    "\n",
    "#     if num_batches == 0:\n",
    "#         raise ValueError(\"Batch size is larger than the number of data points.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "714e1348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a method to generate the next character\n",
    "def predict(net, inputs, h, top_k=None):\n",
    "        ''' Given a onehot encoded character, predict the next character.\n",
    "            Returns the predicted onehot encoded character and the hidden state.\n",
    "        Arguments:\n",
    "            net: the lstm model\n",
    "            inputs: input to the lstm model. shape (batch, time_step/length_of_smiles, input_size) with batchsize of 1\n",
    "            h: hidden state (h,c)\n",
    "            top_k: int. sample from top k possible characters\n",
    "            \n",
    "        '''\n",
    "        # detach hidden state from history\n",
    "        h = tuple([each.data for each in h])\n",
    "        # get the output of the model\n",
    "        out, h = net(inputs, h)\n",
    "        # get the character probabilities\n",
    "        p = out.data\n",
    "\n",
    "        # get top characters\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(17) #index to choose from\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        # select the likely next character with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        # return the onehot encoded value of the predicted char and the hidden state\n",
    "        output = np.zeros(inputs.detach().numpy().shape)\n",
    "        output[:,:,char] = 1\n",
    "        output = torch.tensor(output,dtype=torch.float)\n",
    "        return output, h\n",
    "\n",
    "# Declaring a method to generate new text\n",
    "def sample(net, encoder, prime=['^'], top_k=None):\n",
    "    \"\"\"generate a smiles string starting from prime. I use 'SOS' (start of string) and 'EOS'(end of string). \n",
    "    You may need to change this based on your starting and ending character.\n",
    "\n",
    "    \"\"\"\n",
    "    net.eval() # eval mode\n",
    "    # get initial hidden state with batchsize 1\n",
    "    h = net.init_state(1)\n",
    "    # First off, run through the prime characters\n",
    "    chars=[]\n",
    "    for ch in prime:\n",
    "        ch = encoder.transform(np.array([ch]).reshape(-1, 1)) #(1,17)\n",
    "        ch = torch.tensor(ch,dtype=torch.float).reshape(1,1,17)\n",
    "        char, h = predict(net, ch, h, top_k=top_k)\n",
    "    chars.append(char)\n",
    "    end  = encoder.transform(np.array(['$']).reshape(-1, 1))\n",
    "    end = torch.tensor(end,dtype=torch.float).reshape(1,1,17)\n",
    "\n",
    "    # Now pass in the previous character and get a new one\n",
    "    while not torch.all(end.eq(chars[-1])):\n",
    "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "    chars =[c.detach().numpy() for c in chars]\n",
    "    chars = np.array(chars).reshape(-1,17)\n",
    "    chars = encoder.inverse_transform(chars).reshape(-1)\n",
    "    return ''.join(chars[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "55b394d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object batches_gen at 0x7fa7e42fd2e0>\n",
      "X_batch shape: torch.Size([32, 73, 17])\n",
      "y_batch shape: torch.Size([32, 73, 17])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gen = batches_gen(smile_indicies, 32, encoder)\n",
    "print(gen)\n",
    "\n",
    "# Get the first batch\n",
    "X_batch_test, y_batch_test = next(gen)\n",
    "\n",
    "# Print the shape of the batch data\n",
    "\n",
    "print('X_batch shape:', X_batch_test.shape)\n",
    "print('y_batch shape:', y_batch_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "51d71ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "input_size = 17\n",
    "output_size = 17 \n",
    "hidden_size = 32\n",
    "n_layers = 1\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "362f131a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(17, 32, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=17, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the model, loss function, and optimizer\n",
    "lstm = LSTM(input_size, hidden_size, output_size, n_layers)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "loss_func = nn.MSELoss()\n",
    "print(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c8f34a67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss: 0.04570604860782623\n",
      "Epoch 10, Batch 0, Loss: 0.009050055406987667\n",
      "Epoch 20, Batch 0, Loss: 0.008065683767199516\n",
      "Epoch 30, Batch 0, Loss: 0.007313530892133713\n",
      "Epoch 40, Batch 0, Loss: 0.006817704066634178\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x_batch, y_batch) in enumerate(batches_gen(smile_indicies, batch_size, encoder)):\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Initialize hidden state\n",
    "        h_state, c_state = lstm.init_state(batch_size)\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred, h = lstm(x_batch, (h_state, c_state))\n",
    "        h_state = h_state.detach()\n",
    "        c_state = c_state.detach()\n",
    "        loss = loss_func(y_pred, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print the loss every 100 batches\n",
    "        if epoch % 10 == 0 and i % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Batch {i}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "206c1473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(translate_smiles[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0bfb1f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[H]OC([H])([H])C([H])(C([H])([H()[H1([[H][H]'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(lstm, encoder, prime=['^'], top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990fe6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
